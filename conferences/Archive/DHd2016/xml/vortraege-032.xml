<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="vortraege-032">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>Über den Mehrwert der Vernetzung von OCR-Verfahren zur Erfassung von Texten des 17. Jahrhunderts</title>
        <author>
          <name>
            <surname>Boenig</surname>
            <forename>Matthias</forename>
          </name>
          <affiliation>Berlin-Brandenburgische Akademie der Wissenschaften - Berlin, Deutschland</affiliation>
          <email>boenig@bbaw.de</email>
        </author>
        <author>
          <name>
            <surname>Würzner</surname>
            <forename>Kay-Michael</forename>
          </name>
          <affiliation>Berlin-Brandenburgische Akademie der Wissenschaften - Berlin, Deutschland</affiliation>
          <email>wuerzner@bbaw.de</email>
        </author>
        <author>
          <name>
            <surname>Binder</surname>
            <forename>Arne</forename>
          </name>
          <affiliation>Berlin-Brandenburgische Akademie der Wissenschaften - Berlin, Deutschland</affiliation>
          <email>binder@informatik.hu-berlin.de</email>
        </author>
        <author>
          <name>
            <surname>Springmann</surname>
            <forename>Uwe</forename>
          </name>
          <affiliation>Centrum für Informations- und Sprachverarbeitung - Ludwig-Maximilians-Universität München, Deutschland</affiliation>
          <email>springmann@cis.uni-muenchen.de</email>
        </author>
      </titleStmt>
      <editionStmt>
        <edition>
          <date>2015-10-18T15:21:00Z</date>
        </edition>
      </editionStmt>
      <publicationStmt>
        <publisher>Paul Arthur, University of Western Sidney</publisher>
        <address>
          <addrLine>Locked Bag 1797</addrLine>
          <addrLine>Penrith NSW 2751</addrLine>
          <addrLine>Australia</addrLine>
          <addrLine>Paul Arthur</addrLine>
        </address>
      </publicationStmt>
      <sourceDesc>
        <p>Converted from a Word document </p>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <appInfo>
        <application ident="DHCONVALIDATOR" version="1.15">
          <label>DHConvalidator</label>
        </application>
      </appInfo>
    </encodingDesc>
    <profileDesc>
      <textClass>
        <keywords scheme="ConfTool" n="category">
          <term>Vortrag</term>
        </keywords>
        <keywords scheme="ConfTool" n="subcategory">
          <term></term>
        </keywords>
        <keywords scheme="ConfTool" n="keywords">
          <term>OCR</term>
          <term>17. Jahrhundert</term>
          <term>Texterfassung</term>
          <term>Ocropus</term>
          <term>Tesseract</term>
        </keywords>
        <keywords scheme="ConfTool" n="topics">
          <term>Umwandlung</term>
          <term>Datenerkennung</term>
          <term>Transkription</term>
          <term>Programmierung</term>
          <term>Modellierung</term>
          <term>Annotieren</term>
          <term>Bearbeitung</term>
          <term>Computer</term>
          <term>Datei</term>
          <term>Text</term>
        </keywords>
      </textClass>
    </profileDesc>
  </teiHeader>
  <text>
    <body>
      <div type="div1" rend="DH-Heading1">
        <head>Einleitung</head>
        <p>Dieser Beitrag stellt eine neuartige Methode zur optischen Zeichenerkennung (
          <hi rend="italic">Optical Character Recognition, </hi>OCR) speziell für Textvorlagen des 17. Jahrhunderts vor. Anstatt ein neues OCR-Verfahren zu entwickeln, werden zwei etablierte Open-Source-Lösungen genutzt. Die Ausgaben der Programme werden computergestützt kombiniert, um so eine möglichst genaues Textergebnis zu erhalten. Die Besonderheiten und die Güte der Methode wird anhand der Texterfassung von Gelegenheitsgedichten von Simon Dach illustriert.
        </p>
        <div xml:id="h.6sg223rxpuol" type="div2" rend="DH-Heading2">
          <head>OCR</head>
          <p>OCR bezeichnet die Gesamtheit von Verfahren, die in der Lage sind, aus
            Rastergrafiken Schriftzeichen zu erkennen. Der Begriff wird sowohl für die
            eigentliche Mustererkennung als auch für den gesamten Prozess der
            Bildverarbeitung verwendet. Letzterer gliedert sich normalerweise in drei
            Schritte: <hi rend="bold">1. Bildoptimierung</hi>: Diese besteht aus der
            Bitonalisierung der Digitalisate, ihrer Begradigung (sog. <hi rend="italic"
            >Deskewing</hi>) und aus der Entfernung von Artefakten (sog. <hi
            rend="italic">Despeckling</hi>). Außerdem können beim Scannen
            entstandene Wellen in einzelnen Zeilen automatisch begradigt werden (sog.
            <hi rend="italic">Dewarping</hi>). <hi rend="bold">2.
            Strukturerkennung</hi> ( <hi rend="italic">Optical Layout
            Recognition</hi>, OLR): Die einzelnen Seiten werden u. a. in Spalten,
            Absätze und Zeilen gegliedert. <hi rend="bold">3. Mustererkennung
          </hi>(OCR): Für diese Aufgabe gibt es verschiedene Lösungsvorschläge sowohl
          im kommerziellen wie auch im Open-Source-Bereich. Besonders verbreitet sind
          die Software <hi rend="italic">FineReader</hi> der Firma ABBYY sowie <hi
          rend="italic">BITAlpha </hi>aus dem Hause Tomasi, die u. a. von
          Bibliotheken eingesetzt werden. Die bekanntesten Open-Source-Lösungen sind
          das ursprünglich von Hewlett-Packard entwickelte und heute von Google
          betreute <hi rend="italic">Tesseract</hi> (GitHub 2016a) und das
          ursprünglich am DFKI Kaiserslautern entwickelte <hi rend="italic"
          >OCRopus</hi> (GitHub 2016b). </p>
          <p>Grundsätzlich lassen sich bei OCR zwei unterschiedliche Erkennungsansätze unterscheiden: zeichenorientierte Verfahren wie Tesseract vergleichen das Bild eines Zeichens Pixel für Pixel mit einer Datenbasis (dem sog. Modell) und geben das ähnlichste Zeichen zurück. Sequenzorientierte (segmentierungsfreie) Verfahren wie OCRopus legen ein Raster fester Größe über eine Zeile und bestimmen anhand der Folgen der einzelnen Spalten, repräsentiert als Bitvektoren (0 entspricht weiß, 1 schwarz) die wahrscheinlichste Zeichensequenz. </p>
        </div>
        <div xml:id="h.jloxih9r95e7" type="div2" rend="DH-Heading2">
          <head>Gelegenheitsgedichte</head>
          <p>Unsere Studie beschäftigt sich mit OCR am Beispiel von Gelegenheitsgedichten
            des 17. Jahrhunderts, denen durch die von Segebrecht (1977) initiierte
            literaturwissenschaftliche Neubewertung eine zunehmende kulturgeschichtliche
            Bedeutung zukommt (vgl. Klöker 2010: 39). Der Zugriff auf diese Drucke wurde
            durch das <ref target="http://www.vd17.de/index.php?article_id=26"
            >VD17</ref> (HAB 2007-2016)<ref type="note" target="n01" n="1">1</ref> und durch das <hi rend="italic">Handbuch des personalen
            Gelegenheitsschrifttums in europäischen Bibliotheken und Archiven</hi>
            (Garber 2001-2013) erleichtert. Dennoch kann ein digitales Korpus für diese
            Textsorte heute nur als Desiderat wahrgenommen werden. Für Werke von Simon
            Dach ist die Ausgangslage scheinbar besser: Mit der digitalisierten
            vierbändigen Ausgabe von Ziesemer (Ziesemer 1936-1938) steht ein großer Teil
            der heute bekannten Gedichte zur Verfügung (vgl. auch Dach o. J.; TextGrid
            2015). <ref type="note" target="n02" n="2">2</ref> Jedoch trübt sich dieser Eindruck beim textkritischen Blick. <ref type="note" target="n03" n="3">3</ref>
          </p>
          <p>111 Funeralschriften Simon Dachs wurden im Verlauf des DFG-Pilotprojektes zum
            <hi rend="italic">OCR-Einsatz bei der Digitalisierung der
              Funeralschriften der Staatsbibliothek zu Berlin</hi> (2009-2011)
              (Federbusch / Polzin 2013) digitalisiert und per OCR erfasst. Die in der
              vorliegenden Studie genutzten Drucke zeichnen sich dahingehend aus, dass
              eine einheitliche Schrifttype sowie ein einfaches Layout vorliegen. Im
              Unterschied zu Texten des 18. und 19. Jahrhunderts war für diese Drucke noch
              ein relativ hoher manueller Aufwand erforderlich. Die Schrifttypen weisen
              daher eine vergleichsweise hohe Varianz bzgl. ihrer Form auf. Die 111
              Trauergedichte weisen eine Textgenauigkeit von bis zu 95% auf. Der
              Schwerpunkt der folgenden Studie liegt auf der Entwicklung und Prüfung von
              Methoden, die perspektivisch eine korrektere Übertragung der Textquellen aus
              dem 17. Jahrhundert liefern soll. </p>
            </div>
          </div>
          <div xml:id="h.wiw9vn3xlbve" type="div1" rend="DH-Heading1">
            <head>Arbeitsablauf</head>
            <figure>
              <graphic n="1001" width="13.335cm" height="10.107083333333334cm" url="032-image1.png" rend="inline"/>
              <p>
                <hi rend="bold">Abb. 1</hi>: Modell eines vollständigen Erfassungsworkflows
                (diese Studie betrifft die eingefärbten Stationen). </p>
              </figure>
              <p>Abbildung 1 gibt einen Überblick über den Arbeitsablauf der hier vorgestellten Methode. Im Unterschied zu existierenden Workflows unterteilt unser Vorschlag die Bildoptimierung in zwei Phasen: 1.
                <hi rend="italic">global</hi>: Das komplette Digitalisat wird beschnitten, binarisiert, begradigt und von Artefakten befreit. Danach findet die Optische Layouterkennung (OLR) statt. 2.
                <hi rend="italic">lokal</hi>: Die identifizierten Textzonen werden aus dem Bild der Seite ausgeschnitten und nochmals begradigt. Dadurch wird die häufig zu beobachtende Trapezform der Digitalisate, die durch Scannen von Büchern ohne Auftrennen des Buchrückens entsteht, behandelt. Die Bilder für die einzelnen Zonen werden anschließend in Zeilen zerschnitten und den OCR-Engines übergeben.
              </p>
              <p>Unser Vorgehen bei der OCR orientiert sich an der manuellen Texterfassung per <hi
                rend="italic">Double Keying</hi>: Dabei werden Texte von zwei unabhängigen
                Erfassern transkribiert. Im Vergleich der beiden Textversionen werden die
                Unterschiede ermittelt und die korrekte Version ausgewählt. Um den
                Genauigkeitsgewinn durch die Mehrfacherfassung zu erhöhen, wurden zwei
                paradigmatisch verschiedene OCR-Verfahren, Tesseract und OCRopus, mit
                unterschiedlichen Stärken und Schwächen eingesetzt. Beide Open-Source-Programme
                erlauben ein Training auf die vorwendeten Typen und die Anwendung spezifischer
                OCR-Modelle. Dies ist wie Springmann et al. (2015) zeigen ein wesentlicher
                Vorteil gegenüber den meisten Closed-Source-Lösungen, da die mitgelieferten
                OCR-Modelle insbesondere für frühe Druckerzeugnisse bzw. gebrochene Schriften
                sehr schlechte Ergebnisse bzgl. der Textgenauigkeit liefern. Die automatische
                Vereinigung der beiden Textversionen findet im Wesentlichen auf Basis einer
                Textdifferenzberechnung mit Hilfe von <hi rend="italic">diff</hi> (Hunt /
                McIlroy 1976) statt, wobei im Falle von Unterschieden verschiedene
                Bewertungsheuristiken zur Bestimmung der <hi rend="italic">korrekten</hi>
                Textversion eingesetzt werden. Das skizzierte Vorgehen erlaubt auch die
                Kombination von mehr als zwei Textversionen sowie den anschließenden Einsatz von
                OCR-Nachkorrekturverfahren (vgl. z. B. Vobl et al. 2014). </p>
              </div>
              <div xml:id="h.yuu4lt9yvmnl" type="div1" rend="DH-Heading1">
                <head>Evaluation</head>
                <p>Die Güte der hier vorgestellten Methode wird anhand der Volltexterfassung von
                  Funeralschriften Simon Dachs (vgl. 1.2) evaluiert. Dabei konzentriert sich die
                  Evaluation auf drei Punkte: </p>
                  <list type="unordered">
                    <item>Welchen Einfluss hat die Wahl der Binarisierungsmethode auf die Textgenauigkeit?</item>
                    <item>Wie groß ist der Unterschied zwischen einem Standardmodell und einem speziell für die zu erfassenden Texte trainierten Modell bzgl. der Textgenauigkeit?</item>
                    <item>Kann die Vereinigung zweier durch OCR erzeugter Texte die Textgenauigkeit erhöhen?</item>
                  </list>
                  <p>Ein typisches Beispiel für die Untersuchungsgrundlage sowie die entsprechenden OCR-Ausgaben gibt Abbildung 2.</p>
                  <figure>
                    <graphic n="1002" width="16.00113888888889cm" height="8.960555555555555cm" url="032-image2.png" rend="inline"/>
                    <p>
                      <hi rend="bold">Abb. 2</hi>: Vergleich der OCR-Ergebnisse. </p>
                    </figure>
                  </div>
                  <div xml:id="h.2eo3ulvoieam" type="div1" rend="DH-Heading1">
                    <head>Material</head>
                    <div xml:id="h.wnodj54ezvdz" type="div2" rend="DH-Heading2">
                      <head>Ground Truth</head>
                      <p>Voraussetzung für die Evaluation und das Modelltraining ist fehlerfreier
                        Volltext ( <hi rend="italic">Ground Truth</hi>). Um für die Studie
                        entsprechende Daten zu gewinnen, wurde eine manuelle Korrektur aller 111
                        Texte vorgenommen. Die Korrektur schloss nicht nur die Text-, sondern auch
                        die datenstrukturelle Ebene ein. Der Aufwand belief sich auf 150 Stunden. Im
                        Ergebnis liegen alle Texte im DTA-Basisformat vor und sind über die
                        Qualitätssicherungsplattform <ref
                        target="http://www.deutschestextarchiv.de/dtaq">DTAQ</ref> zugänglich. </p>
                      </div>
                      <div xml:id="h.ns21lwuxkxmp" type="div2" rend="DH-Heading2">
                        <head>Materialauswahl</head>
                        <p>Für das Training der spezifischen OCR-Modelle wurden 30 Seiten Ground-Truth zufällig ausgewählt. Für die Evaluation der Modelle wurden 25 andere zufällig ausgewählte Seiten verwendet.</p>
                      </div>
                      <div xml:id="h.b6hw3l3e9xjl" type="div2" rend="DH-Heading2">
                        <head>Referenzlexikon</head>
                        <p>Zur Vereinigung beider OCR-Versionen wurde ein Referenzlexikon gültiger historischer Schreibungen des 17. Jahrhunderts herangezogen. Dazu wurden Wortformen (
                          <hi rend="italic">n</hi>=217067) aus DTA-Texten dieses Zeitraums extrahiert.
                        </p>
                      </div>
                    </div>
                    <div xml:id="h.x3h4k58kl4a6" type="div1" rend="DH-Heading1">
                      <head>Durchführung</head>
                      <div xml:id="h.uc8w3e3rtefw" type="div2" rend="DH-Heading2">
                        <head>Vorverarbeitung</head>
                        <p>Für Beschneidung und Begradigung wurde das Programm <hi rend="italic"
                          >Scantailor</hi> (GitHub 2016 a) eingesetzt. Für die Binarisierung,
                          Artefaktbereinigung und Zeilenglättung wurde sowohl Scantailor als auch das
                          in OCRopus enthaltene Werkzeug <hi rend="italic">nlbin</hi> verwendet. </p>
                        </div>
                        <div xml:id="h.2pikwls1fou8" type="div2" rend="DH-Heading2">
                          <head>OLR</head>
                          <p>Die einzelnen Textzonen (Abschnitte und Kustoden) wurden mit Hilfe von <hi
                            rend="italic">Leptonica</hi> (Bloomberg 2001-2015) lokalisiert und
                            manuell nachkorrigiert. Für die Untergliederung der Zonen in Zeilen wurde
                            ebenfalls Leptonica eingesetzt. </p>
                          </div>
                          <div xml:id="h.4hfubd3yu7tf" type="div2" rend="DH-Heading2">
                            <head>OCR</head>
                            <p>Die Zeichenerkennung erfolgte sowohl mit OCRopus als auch mit Tesseract. Die erste Versuchsreihe basierte auf mitgelieferten Modellen. Für die zweite Versuchsreihe wurden die OCR-Programme mit Ground-Truth-Daten trainiert. Für das Training der OCRopus-Modelle wurde OCRopus eingesetzt. Dabei wurde für das Training aus Gründen der Modellvergleichbarkeit eine feste Anzahl von Iterationsschritten (
                              <hi rend="italic">n</hi>=30000) festgelegt. Die Tesseract-Modelle wurden mit Hilfe von
                              <hi rend="italic">VietOCR</hi> erstellt.
                            </p>
                          </div>
                          <div xml:id="h.kw5xpj4qoltv" type="div2" rend="DH-Heading2">
                            <head>Textvereinigung</head>
                            <p>Die Textvereinigung wurde in
                              <hi rend="italic">Python</hi> mit Hilfe des Moduls
                              <hi rend="italic">difflib</hi> implementiert. Neben dem Referenzlexikon standen zur Konfliktauflösung auch die von den OCR-Programmen zurückgelieferten Konfidenzen auf Zeichenebene zur Verfügung. Waren sich die beiden Engines bzgl. eines Wortes bzw. einer Textsequenz uneins, wurde zunächst dem Wort Vorrang gegeben, dass sich im Referenzlexikon befindet. Konnte dort keine der beiden Versionen gefunden werden, wurde die Entscheidung auf Basis der Konfidenzwerte getroffen.
                            </p>
                          </div>
                          <div xml:id="h.v61tqy2cwm7u" type="div2" rend="DH-Heading2">
                            <head>Qualitätsmessung</head>
                            <p>Die Bestimmung der Textqualität erfolgte durch Messung des Anteils falsch erkannter Zeichen (Fehlerrate in Prozent) im Vergleich zum fehlerfreien Volltext.</p>
                          </div>
                        </div>
                        <div xml:id="h.r6svsi1idfgr" type="div1" rend="DH-Heading1">
                          <head>Ergebnisse und Diskussion</head>
                          <p>Tabelle 1 gibt einen Überblick über die Ergebnisse der Evaluation bzgl. der
                            Fehlerrate auf Zeichenebene unter Berücksichtigung der Vorverarbeitung des
                            Trainings- und Testmaterials, der Modellklasse (standard vs. spezifisch) und der
                            eingesetzten OCR-Software (OCRopus, Tesseract). Das beste (<hi
                            rend="bold color(38761D)">grün</hi>) und das schlechteste Ergebnis (<hi
                            rend="bold color(980000)">rot</hi>) sind hervorgehoben. Da wir keinen
                            Einfluss auf die Vorverarbeitung der Trainingsmaterialien der mitgelieferten
                            Modelle haben, ist die Matrix in dieser Hinsicht unvollständig. </p>
                            <figure>
                              <graphic n="1004" url="032-image4.svg" rend="inline"/>
                              <p>
                                <hi rend="bold">Tab. 1</hi>: Darstellung der Ergebnisse auf Einzel-OCR-Ebene im Bezug auf
                                Vorverarbeitungsmethode für Trainings- und Testmaterial, Modelltyp und verwendete
                                OCR-Software. </p>
                              </figure>
                              <p>Die geringste erreichte Fehlerrate (3,89 %) liegt etwa im Bereich der
                                Textgenauigkeit der 111 Gedichte aus der Pilotstudie von Federbusch (Federbusch
                                / Polzin 2013). Die Fehlerrate von Tesseract ist jeweils höher als die von
                                OCRopus. Der sequenzorientierte Ansatz hat klare Vorteile bei der Erkennung von
                                Schriftzeichen, die die typischen Charakteristika früher Drucke aufweisen. <ref type="note" target="n05" n="5">5</ref>
                              </p>
                              <p>Desweiteren zeigt sich, dass die Vorverarbeitung mit nlbin für Tesseract sowohl auf Trainings- als auch auf Testebene jeweils schlechtere Ergebnisse bringt. Für OCRopus sind die Ergebnisse bzgl. der Vorverarbeitung differenzierter: Die beste Kombination liefert eine Vorverarbeitung des Trainingsmaterials mit nlbin bei einer nachfolgenden Vorverarbeitung des Testmaterials mit Scantailor. Unterschiede im Ergebnis der Vorverarbeitung beider Programme illustriert Abbildung 3.</p>
                              <figure>
                                <graphic n="1003" width="16.002cm" height="2.806347222222222cm" url="032-image3.png" rend="inline"/>
                                <p> Abb. 3: Bild einer Textzeile nach der Vorverarbeitung mit nlbin (oben) und
                                  Scantailor (unten). </p>
                                </figure>
                                <p>Die von Scantailor durchgeführte Bildvorverarbeitung ist deutlich normativer und für einen zeichenorientierten Ansatz wie Tesseract besser geeignet. Das Training sequenzorientierter Ansätze leidet unter dieser Vergröberung.</p>
                                <p>Es zeigt sich erneut, dass spezifisch trainierte Modelle eine massive Textgenauigkeitsverbesserung mit sich bringen können (vgl. auch Springmann et al. 2015).</p>
                                <div xml:id="h.b53zdskw38g8" type="div2" rend="DH-Heading2">
                                  <head>Textvereinigung</head>
                                  <p>Betrachtet man die Beispielausgaben in Abbildung 2, so wird der
                                    Qualitätsunterschied zwischen beiden OCR-Programmen ersichtlich. An
                                    einzelnen Stellen jedoch (z. B. Großbuchstaben am Anfang der Zeile im
                                    letzten Abschnitt) hat Tesseract Erkennungsvorteile.</p>
                                    <p>Ausgehend von diesem Befund wurde der jeweils genaueste Text von OCRopus und Tesseract miteinander vereinigt. Es hat sich gezeigt, dass die Konfidenzen, die die Programme für jedes Zeichen zurückliefern, kein verlässliches Kriterium sind, um Konflikte aufzulösen. Die Fehlerrate nimmt zu. Die Strategie, Wörter bzw. Sequenzen zu bevorzugen, die sich im Referenzlexikon befinden, hat dagegen eine messbare Verbesserung mit sich gebracht. Die Anzahl der falsch erkannten Zeichen konnte um 14 % reduziert werden (Fehlerrate 3,34 %). Es ist zu vermuten, dass der Effekt größer wäre, wenn zwei OCR-Ergebnisse mit vergleichbarer Qualität vorlägen. Dies bleibt jedoch zum jetzigen Zeitpunkt für Drucke des 17. Jahrhunderts ein Desiderat.</p>
                                  </div>
                                </div>
                              </body>
                              <back>
                                <div type="Notes">
                                  <note xml:id="n01" n="1">Verzeichnis der im deutschen Sprachraum erschienenen Drucke des 17. Jahrhunderts.</note>
                                  <note xml:id="n02" n="2">Vgl auch Dach (o. J.) in <ref target="http://www.zeno.org/Literatur/M/Dach,+Simon/Gedichte">http://www.zeno.org/Literatur/M/Dach,+Simon/Gedichte</ref> sowie <ref target="https://textgrid.de/digitale-bibliothek">TextGrid</ref> (2015).</note>
                                  <note xml:id="n03" n="3">„Ziesemers Dach-Ausgabe ist textlich zu wenig genau, um auch für die dort abgedruckten, fast ausnahmslos deutschsprachigen, Gedichte den Rückgriff auf die kasualen Einzeldrucke und andere zeitgenössische Ausgaben entbehren zu können. Jede Stichprobe erweist für jedes einzelne Gedicht Transkriptionsfehler und unerklärte Texteingriffe.“ (Walter 2008: 466)</note>
                                  <note xml:id="n05" n="5">Für Frakturdrucke des 19. Jahrhunderts ist ein solch starker Unterschied zwischen den Tesseract und OCRopus nicht nachgewiesen.</note>
                                </div>
                                <div type="bibliogr">
                                  <listBibl>
                                    <head>Bibliographie</head>
                                    <bibl><hi rend="bold">Bloomberg, Dan</hi> (2001-2015): Leptonica <ref
                                    target="http://www.leptonica.com/">http://www.leptonica.com/</ref>
                                    [letzter Zugriff: 15. Oktober 2015].</bibl>
                                    <bibl><hi rend="bold">Dach, Simon</hi> (o. J.): <hi rend="italic">Gedichte</hi>
                                    <ref target="http://www.zeno.org/Literatur/M/Dach,+Simon/Gedichte">
                                      http://www.zeno.org/Literatur/M/Dach,+Simon/Gedichte</ref> [letzter
                                      Zugriff 15. Oktober 2015]. </bibl>
                                      <bibl><hi rend="bold">Federbusch, Maria / Polzin, Christian</hi> (2013): <hi
                                      rend="italic">Volltext via OCR - Möglichkeiten und Grenzen</hi>.
                                      Testszenarien zu den Funeralschriften der Staatsbibliothek zu Berlin -
                                      Preußischer Kulturbesitz. Berlin Staatsbibliothek zu Berlin <ref
                                      target="http://staatsbibliothek-berlin.de/fileadmin/user_upload/zentrale_Seiten/historische_drucke/pdf/SBB_OCR_STUDIE_WEBVERSION_Final.pdf "
                                      >http://staatsbibliothek-berlin.de/fileadmin/user_upload/zentrale_Seiten/historische_drucke/pdf/SBB_OCR_STUDIE_WEBVERSION_Final.pdf</ref>
                                      [letzter Zugriff 15. Oktober 2015].</bibl>
                                      <bibl><hi rend="bold">Garber, Klaus</hi> (2001-2013): <hi rend="italic">Handbuch
                                      des personalen Gelegenheitsschrifttums in europäischen Bibliotheken und
                                      Archiven</hi>. 13 Bände. Hildesheim / Zürich / New York: Olms /
                                      Weidmann. </bibl>
                                      <bibl><hi rend="bold">GitHub Inc.</hi> (2016a): <hi rend="italic"
                                      >ScanTailor</hi>
                                      <ref target="http://scantailor.org">http://scantailor.org/</ref> [letzter
                                      Zugriff 15. Oktober 2015].</bibl>
                                      <bibl><hi rend="bold">GitHub Inc.</hi> (2016b): <hi rend="italic">OCRopus</hi>
                                      <ref target="https://github.com/tmbdev/ocropy"
                                        >https://github.com/tmbdev/ocropy</ref> [letzter Zugriff 15. Oktober
                                        2015]. </bibl>
                                        <bibl><hi rend="bold">GitHub Inc.</hi> (2016c): <hi rend="italic">Tesseract</hi>
                                        <ref target="https://github.com/tesseract-ocr"
                                          >https://github.com/tesseract-ocr</ref> [letzter Zugriff 15. Oktober
                                          2015].</bibl>
                                          <bibl><hi rend="bold">HAB = Herzog August Bibliothek Wolfenbüttel</hi>
                                          (2007-2016): <hi rend="italic">VD17</hi>. Das Verzeichnis der im deutschen
                                          Sprachraum erschienenen Druck des 17. Jahrhunderts <ref
                                          target="http://www.vd17.de/index.php?category_id=1&amp;article_id=1&amp;clang=0"
                                          >http://www.vd17.de/index.php?category_id=1&amp;article_id=1&amp;clang=0</ref>.</bibl>
                                          <bibl><hi rend="bold">Hunt, James W. / McIlroy, M. Douglas</hi> (1976): "An
                                          Algorithm for Differential File Comparison" in: <hi rend="italic">Computing
                                          Science Technical Report</hi> (Bell Laboratories) 41 <ref
                                          target="http://www.cs.dartmouth.edu/~doug/diff.pdf"
                                          >http://www.cs.dartmouth.edu/~doug/diff.pdf</ref></bibl>
                                          <bibl><hi rend="bold">Klöker, Martin</hi> (2010): "Das Testfeld der Poesie.
                                          Empirische Betrachtungen aus dem Osnabrücker Projekt zur 'Erfassung und
                                          Erschließung von personalen Gelegenheitsgedichten'", in: Keller, Andreas /
                                          Lösel, Elke / Wels, Ulrike / Wels, Volkhard (eds.): <hi rend="italic"
                                          >Theorie und Praxis der Kasualdichtung in der Frühen Neuzeit</hi> (=
                                          Chloe. Beihefte zu Daphne 43). Amsterdam / New York: Rodopi 39-84. </bibl>
                                          <bibl><hi rend="bold">Python Software Fundation</hi> (1990-2016): <hi
                                          rend="italic">difflib - Helpers for Computing Deltas </hi><ref
                                          target="https://docs.python.org/2/library/difflib.html"
                                          >https://docs.python.org/2/library/difflib.html</ref> [letzter Zugriff
                                          15. Oktober 2015].</bibl>
                                          <bibl><hi rend="bold">Segebrecht, Wulf </hi>(1977): <hi rend="italic">Das
                                          Gelegenheitsgedicht</hi>. Ein Beitrag zur Geschichte und Poetik der
                                          deutschen Lyrik. Suttgart: Metzler.</bibl>
                                          <bibl><hi rend="bold">Springmann, Uwe / Lüdeling, Anke / Schremmer, Felix</hi>
                                          (2015): "Zur OCR frühneuzeitlicher Drucke am Beispiel des RIDGES-Korpus von
                                          Kräutertexten (Poster)", in: <hi rend="italic">Tagung der DHd (Digitale
                                          Geisteswissenschaften im deutschsprachigen Raum)</hi>, Graz <ref
                                          target="https://www.linguistik.hu-berlin.de/de/institut/professuren/korpuslinguistik/mitarbeiter-innen/anke/pdf/SpringmannLuedelingSchremmer2015.pdf"
                                          >https://www.linguistik.hu-berlin.de/de/institut/professuren/korpuslinguistik/mitarbeiter-innen/anke/pdf/SpringmannLuedelingSchremmer2015.pdf</ref>
                                          [letzter Zugriff 15. Oktober 2015].</bibl>
                                          <bibl><hi rend="bold">TextGrid </hi>(2015): <hi rend="italic">Die digitale
                                          Bibliothek bei TextGrid</hi>
                                          <ref target="https://textgrid.de/digitale-bibliothek"
                                            >https://textgrid.de/digitale-bibliothek</ref> [letzter Zugriff 15.
                                            Oktober 2015] </bibl>
                                            <bibl><hi rend="bold">VietOCR</hi>
                                            <ref target="http://vietocr.sourceforge.net/"
                                              >http://vietocr.sourceforge.net/</ref> [letzter Zugriff: 15. Oktober
                                              2015].</bibl>
                                              <bibl><hi rend="bold">Vobl, Thorsten / Gotscharek, Annette / Reffle, Uli /
                                                Ringlstetter, Christoph / Schulz, Klaus U.</hi> (2014): "PoCoTo - an
                                                open source system for efficient interactive postcorrection of OCRed
                                                historical texts" in: <hi rend="italic">Proceedings of the First
                                                International Conference on Digital Access to Textual Cultural Heritage
                                                (DATeCH '14)</hi>: 57-61 <ref
                                                target="http://dl.acm.org/citation.cfm?id=2595197"
                                                >http://dl.acm.org/citation.cfm?id=2595197</ref> [letzter Zugriff 15.
                                                Oktober 2015].</bibl>
                                                <bibl><hi rend="bold">Walter, Axel E.</hi>(2008): "Dach digital? Vorschläge zu
                                                einer Bibliographie und Edition des Gesamtwerks von Simon Dach nebst einigen
                                                erläuterten Beispielen vernachlässigter bzw. unbekannter Gedichte", in:
                                                Walter, Axel E. (ed.) in: <hi rend="italic">Simon Dach (1605–1659)</hi>.
                                                Werk und Nachwirken. Tübingen: Niemeyer: 465-522.</bibl>
                                                <bibl><hi rend="bold">Ziesemer, Walter</hi> (ed.) (1936-1938): <hi rend="italic"
                                                >Simon Dach: Gedichte</hi>. Vier Bände. Halle an der Saale:
                                                Niemeyer.</bibl>
                                                <lb/>
                                              </listBibl>
                                            </div>
                                          </back>
                                        </text>
                                      </TEI>
