<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:id="257_final-G_TZELMANN_Germaine_Wie_sich_die_Bilder_gleichen__Bild_hnlic" xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Wie sich die Bilder gleichen. Bildähnlichkeitssuche in Drucken des 16. Jahrhunderts</title>
                <author>
                    <persName>
                        <surname>Götzelmann</surname>
                        <forename>Germaine</forename>
                    </persName>
                    <affiliation>Karlsruher Institut für Technologie, Deutschland</affiliation>
                    <email>germaine.goetzelmann@kit.edu</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2018-10-14T20:26:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <t:publisher xmlns:t="http://www.tei-c.org/ns/1.0">Patrick Sahle, im Auftrag des Verbands Digital Humanities im deutschsprachigen Raum e.V.</t:publisher>
                <t:address xmlns:t="http://www.tei-c.org/ns/1.0">
                    <t:addrLine>Universität zu Köln</t:addrLine>
                    <t:addrLine>Cologne Center for eHumanities</t:addrLine>
                    <t:addrLine>Albertus-Magnus-Platz</t:addrLine>
                    <t:addrLine>50923 Köln</t:addrLine>
                </t:address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Posterpräsentation</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>Bildähnlichkeitssuche</term>
                    <term>Layoutanalyse</term>
                    <term>Web Annotation Data Model</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>Bilderfassung</term>
                    <term>Annotieren</term>
                    <term>Netzwerkanalyse</term>
                    <term>Bilder</term>
                    <term>Metadaten</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <p>Die Anzahl von Buchdigitalisaten weltweit hat längst eine Datenmenge erreicht, die sich rein manueller Auswertung entzieht (HathiTrust verzeichnet beispielsweise tagesaktuell 5.860.937.950 digitalisierte Buchseiten). Aus diesem Grund gilt es, zusätzliche Auswertungsmethoden und Workflows zu entwickeln, die solche Digitalisatsdaten analysierbar und durchsuchbar machen und damit über explorative Ansätze und Zufallsfunde hinausgehen. Ein Beispiel für eine solche Auswertungsmethode stellt die Suche nach Bildähnlichkeiten zwischen Buchillustrationen dar, die wichtige Aufschlüsse über Zusammenhänge zwischen einzelnen Buchexemplaren, aber auch über die Signifikanz von Bildformeln sowie den Zusammenhang von Bild- und Texttradition liefern kann.</p>
            <div type="div1" rend="DH-Heading1">
                <head>Anwendungsfall: Drucke des 16. Jahrhunderts</head>
                <p>In deutschen (Wiegen-)Drucke des 15. und 16. Jahrhunderts insb. volksprachlicher Texte werden dem geschriebenen Wort zahlreiche Illustrationen zur Seite gestellt. Während diese zu Beginn noch große Textnähe aufweisen, wird für sie zusehends konstitutiv, dass sie bereits von vornherein polyvalent und multifunktional angelegt sind (Vgl. Ott, 1999), um leicht in verschiedene Textzusammenhänge gestellt werden zu können. Dies spiegelt unter anderem ökonomische Interessen wider. Holzschnittvorlagen werden für immer neue Bücher wiederverwendet und somit rekontextualisiert. Die Einschätzung dieser Bildübernahmen reicht in der Forschung in den Einzelfällen von ‚reflektiert’ bis ‚sorglos’ (Speth 2017, 305). </p>
                <p>Im VD16 stehen von den ca. 106000 verzeichneten Drucken des 16. Jahrhunderts etwa 68500 mit Link zu einem Komplettdigitalisat zur Verfügung, die aus den verschiedensten Digitalisierungsprojekten stammen. Dies entspricht auch bei vorsichtigster Schätzung mehreren Millionen von Einzelseiten. Die Posterpräsentation stellt einen Workflow vor, der ausgehend von diesen Digitalisaten diejenigen Buchseiten mit Illustrationen einer Bildähnlichkeitssuche unterzieht und so die Verwendung gleicher und ähnlicher Bilder in verschiedenen Buchexemplaren sichtbar macht.</p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Workflow zur Bildähnlichkeitssuche</head>
                <p>Bildähnlichkeitssuchen erschließen zusehends digitale Bestände, dabei lassen sich zwei Vorgehensweisen unterschieden: die explorative Suche, wie sie die proprietäre Bildähnlichkeitssuche der Bayerischen Staatsbibliothek (BSB) bietet und die strukturierte Suche, wie sie im Projekt 15cBOOKTRADE mittels 
                    <hi rend="italic">VGG Image Search Engine</hi> (VISE)) umgesetzt ist. VISE kommt auch im vorgestellten Workflow zum Einsatz. In einem ersten Schritt dieses Workflows werden aus Digitalisaten die Einzelseiten als Bilddaten extrahiert. In einem zweiten Schritt wird dann auf Methoden der Layoutanalyse zurückgegriffen, um Illustrationen als Bildregionen zu segmentieren. Für den Anwendungsfall der Drucke des 16. Jahrhunderts bietet sich das Tool 
                    <hi rend="italic">LAREX</hi> an, das im Workflow vollautomatisch angewendet wird. Mit diesem Workflowschritt geht eine Reduktion des Suchraums für die Bildähnlichkeitssuche von allen Einzelseiten auf Seiten mit erkannten Bildregionen einher – in der Praxis bedeutet dies eine Verringerung der Seitenmenge um über 75%. Anhand der Segmentierungsergebnisse wird in einem dritten Schritt die Bildähnlichkeitssuche als vollständige Suche durchgeführt: Jede segmentierte Bildregion wird mit allen anderen Seiten mit erkannten Bildregionen verglichen. Aus den Ergebnissen der Bildsuche werden in Schritt vier Ergebnisgraphen erzeugt, die die Treffer ähnlicher Bildregionen abbilden. Dabei erfolgt die Graphgenerierung so, dass nur reziproke Ergebnisse der Bildsuche aufgenommen werden. Zwei Bildregionen im Graph werden nur verbunden, wenn Bildregion A Bildregion B findet und umgekehrt (Abbildung 1). Die einzelnen Bildregionen können anschließend nach Buchzugehörigkeit zusammengefasst werden, woraus sich ein Netzwerk von Buchexemplaren ergibt, dessen gewichtete Verbindungen die Anzahl wiederverwendeter Illustrationen darstellen. Mit diesem Ergebnis eröffnen sich die eigentlichen Auswertungsmöglichkeiten unter Einbeziehung der vorliegenden Metadaten.
                </p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Workflowergebnisse als Annotationen</head>
                <p>Im automatischen Workflow sind die einzelnen Schritte sowohl parametrisierbar als auch gegen andere Werkzeuge mit gleicher Funktion (beispielsweise andere Layoutanalyse-Tools) austauschbar. Daher sind zum einen flexible Neudurchläufe mit anderen Werten wünschenswert, zum anderen müssen die Ergebnisse der einzelnen Schritte gut vergleichbar sein. Mit diesem Ziel werden die Ergebnisse der Einzelschritte 2-5 in einem einheitlichen, standardisierten Format gemäß der W3C-Empfehlung des 
                    <hi rend="italic">Web Annotation Data Model</hi> in einem Annotationsserver gespeichert. Diese Annotationsform ermöglicht perspektivisch auch die Verbindung mit Metadaten in der Linked Open Data Cloud sowie Veröffentlichung und Rückbindung an die öffentlich zugänglichen Digitalisatsdaten der Bibliotheken zur Nachnutzung für weitere Forschungsfragen.
                </p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Herausforderungen</head>
                <p>Methodisch kann mit dem beschriebenen Verfahren nicht klar zwischen identischen und ähnlichen Bildern unterschieden werden. Strukturelle Ähnlichkeiten wie großflächige gleichartige Muster in den Holzschnitten können zu systematischen Fehl-Erkennungen führen, sind jedoch relativ leicht herauszufiltern. Anders steht es um korrekte Treffer ohne Signifikanz für die Fragestellung, beispielsweise Druckermarken, Initialen oder Schmuckelemente. Diese müssen ggf. manuell bereinigt werden, was allerdings mit einer Benutzeroberfläche zur Darstellung der einzelnen Regionengraphen mit vergleichsweise geringem Aufwand auch für mehrere hundert Graphen durchführbar ist. Herausforderungen stellen auch die Schnittstellen an Beginn und Ende des Workflows dar. In den Onlinebibliographien fehlen häufig noch automatische Exportmöglichkeiten. Auch die Digitalisate sind oft nur manuell zugreifbar, sodass hier ein automatisches Anstoßen des Workflows basierend auf Rechercheergebnissen kaum möglich ist. Die Vielzahl verschiedener Varianten von Digitalisatspräsentationen der verschiedenen Bibliotheken machen einen Rückbezug der Ergebnisse auf die öffentlich verfügbaren Digitalisate mühsam – aber gerade hier eröffnet das Konzept des 
                    <hi rend="italic">Web Annotation Data Models</hi> interessante Möglichkeiten.
                </p>
                <figure>
                    <graphic n="1001" width="8.080375cm" height="8.071172222222222cm" url="257_final-0c663dd0af45b5c9fa2606c2c5e53060.png" rend="inline"/>
                    <head>Abbildung 1. Graph von Seiten mit ähnlicher Bildregion</head>
                </figure>
            </div>
        </body>
        <back>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliographie</head>
                    <bibl>
                        <hi rend="bold">Brantl, Markus, / Ceynowa, Klaus / Meiers, Thomas / Wolf, Thomas (2017):</hi> 
                        <hi rend="italic">Visuelle Suche in historischen Werken</hi>, 
                        in: Datenbank Spektrum 17: 53–60.
                    </bibl>
                    <bibl>Hathitrust Statistics and Visualizations: 
                        <ref target="https://www.hathitrust.org/statistics_visualizations">https://www.hathitrust.org/statistics_visualizations</ref> [letzter Zugriff 27.10.18].
                    </bibl>
                    <bibl>
                        <hi rend="bold">Malaspina, Matilde / Zhong, Yujie (2017):</hi> 
                        <hi rend="italic">Image-matching technology applied to Fifteenth-century printed book illustration</hi>, 
                        in: Lettera Matematica 5: 287–292.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Ott, Norbert (1999):</hi> 
                        <hi rend="italic">Leitmedium Holzschnitt</hi>, 
                        in: Die Buchkultur im 15. und 16. Jahrhundert 2, Hamburg: Maximilian-Gesellschaft 163–252.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Reul, Christian / Springmann, Uwe / Puppe, Frank (2017):</hi> 
                        <hi rend="italic">LAREX – A semi-automatic open-source Tool for Layout Analysis and Region Extraction on Early Printed Books</hi>, 
                        in Proceedings of the 2nd International Conference on Digital Access to Textual Cultural Heritage, ACM.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Speth, Sebastian (2017):</hi> 
                        <hi rend="italic">Dimensionen narrativer Sinnstiftung im frühneuhochdeutschen Prosaroman. Textgeschichtliche Interpretation von ‚Fortunatus’ und ‚Herzog Ernst’</hi>, 
                        Berlin/Boston: De Gruyter.
                    </bibl>
                    <bibl>The 15cBOOKTRADE Project: 
                        <ref target="http://15cbooktrade.ox.ac.uk/">http://15cbooktrade.ox.ac.uk/</ref> [letzter Zugriff 27.10.18].
                    </bibl>
                    <bibl>Web Annotation Data Model: 
                        <ref target="https://www.w3.org/TR/annotation-model/">https://www.w3.org/TR/annotation-model/</ref> [letzter Zugriff 27.10.18].
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
